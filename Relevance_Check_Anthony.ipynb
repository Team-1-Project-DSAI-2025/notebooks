{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yv2I6CJ3lDAQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import traceback"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = []\n",
        "df_0 = pd.read_csv(\"chaotic_categories_data.csv\")\n",
        "lst.append(df_0)\n",
        "\n",
        "for i in range(1, 4):\n",
        "    df = pd.read_csv(f\"chaotic_categories_dataset ({i}).csv\")\n",
        "    lst.append(df)\n",
        "\n",
        "df = pd.concat(lst, ignore_index=True)"
      ],
      "metadata": {
        "id": "A0FsMIKHyL7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "98spiOUj6Row",
        "outputId": "e5978089-879f-42ee-c9cc-4f3b63425fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          category  ... creativity_score\n",
              "0  Things You Can Use as a Hat (that are not hats)  ...             0.78\n",
              "1  Things You Can Use as a Hat (that are not hats)  ...             0.65\n",
              "2  Things You Can Use as a Hat (that are not hats)  ...             0.72\n",
              "3  Things You Can Use as a Hat (that are not hats)  ...             0.45\n",
              "4  Things You Can Use as a Hat (that are not hats)  ...             0.82\n",
              "\n",
              "[5 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d03566f5-00b9-4314-947b-ba56d8c37b74\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>answer</th>\n",
              "      <th>relevance_score</th>\n",
              "      <th>creativity_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Things You Can Use as a Hat (that are not hats)</td>\n",
              "      <td>A watermelon half</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Things You Can Use as a Hat (that are not hats)</td>\n",
              "      <td>A colander</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Things You Can Use as a Hat (that are not hats)</td>\n",
              "      <td>A flower pot</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Things You Can Use as a Hat (that are not hats)</td>\n",
              "      <td>A bowl</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Things You Can Use as a Hat (that are not hats)</td>\n",
              "      <td>A traffic cone</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.82</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d03566f5-00b9-4314-947b-ba56d8c37b74')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d03566f5-00b9-4314-947b-ba56d8c37b74 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d03566f5-00b9-4314-947b-ba56d8c37b74');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e2be2317-9301-4fd7-b2bb-c7935ad7a1ea\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e2be2317-9301-4fd7-b2bb-c7935ad7a1ea')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e2be2317-9301-4fd7-b2bb-c7935ad7a1ea button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2030,\n  \"fields\": [\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"Worst Possible Superhero Catchphrases\",\n          \"Worst Possible Fortune Cookie Messages\",\n          \"Things That Would Make Terrible Band Names\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1952,\n        \"samples\": [\n          \"Belly button lint\",\n          \"Diamond rings\",\n          \"We pay in exposure and leftover pizza\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relevance_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23294182861797916,\n        \"min\": 0.05,\n        \"max\": 0.98,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          0.97,\n          0.95,\n          0.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"creativity_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2283575670947411,\n        \"min\": 0.02,\n        \"max\": 0.98,\n        \"num_unique_values\": 95,\n        \"samples\": [\n          0.24,\n          0.93,\n          0.21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    SENTENCE_TRANSFORMERS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SENTENCE_TRANSFORMERS_AVAILABLE = False\n",
        "    print(\"sentence-transformers not available.\")"
      ],
      "metadata": {
        "id": "2ljRW50eoHIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RelevanceChecker:\n",
        "    def __init__(self, approach='auto'):\n",
        "        self.approach = approach\n",
        "        self.model = None\n",
        "        self.vectorizer = None\n",
        "        self.sentence_model = None\n",
        "        self.scaler = None\n",
        "        self.feature_names = []\n",
        "        self.training_stats = {}\n",
        "        self.scaling_required_models = ['neural', 'svm', 'linear']\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        if pd.isna(text):\n",
        "            return \"\"\n",
        "\n",
        "        text = str(text).lower().strip()\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'\\b(teh|hte)\\b', 'the', text)\n",
        "        text = re.sub(r'\\b(adn|nad)\\b', 'and', text)\n",
        "        text = re.sub(r'\\b(taht|htat)\\b', 'that', text)\n",
        "        text = re.sub(r'\\b(ot)\\b', 'to', text)\n",
        "        text = re.sub(r'\\b(fo)\\b', 'of', text)\n",
        "        text = re.sub(r'\\b(cna)\\b', 'can', text)\n",
        "        text = re.sub(r'\\b(tiem)\\b', 'time', text)\n",
        "        text = re.sub(r'[!]{2,}', '!', text)\n",
        "        text = re.sub(r'[?]{2,}', '?', text)\n",
        "        text = re.sub(r'[.]{2,}', '...', text)\n",
        "        text = re.sub(r'[^\\w\\s\\.\\!\\?\\,\\-]', ' ', text)\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        return text\n",
        "\n",
        "    def extract_basic_features(self, categories, answers):\n",
        "        if self.vectorizer is None:\n",
        "            all_texts = categories + answers\n",
        "            self.vectorizer = TfidfVectorizer(\n",
        "                max_features=2000,\n",
        "                ngram_range=(1, 2),\n",
        "                stop_words='english',\n",
        "                min_df=2,\n",
        "                max_df=0.8,\n",
        "                lowercase=True\n",
        "            )\n",
        "            self.vectorizer.fit(all_texts)\n",
        "\n",
        "        category_vectors = self.vectorizer.transform(categories)\n",
        "        answer_vectors = self.vectorizer.transform(answers)\n",
        "\n",
        "        features = []\n",
        "\n",
        "        for i in range(len(categories)):\n",
        "            category = categories[i]\n",
        "            answer = answers[i]\n",
        "\n",
        "            tfidf_similarity = cosine_similarity(\n",
        "                category_vectors[i:i+1],\n",
        "                answer_vectors[i:i+1]\n",
        "            )[0][0]\n",
        "\n",
        "            cat_words = set(category.split())\n",
        "            ans_words = set(answer.split())\n",
        "\n",
        "            common_words = len(cat_words & ans_words)\n",
        "            total_words = len(cat_words | ans_words)\n",
        "            jaccard_similarity = common_words / total_words if total_words > 0 else 0\n",
        "\n",
        "            answer_length = len(answer.split())\n",
        "            category_length = len(category.split())\n",
        "            length_ratio = answer_length / category_length if category_length > 0 else 0\n",
        "\n",
        "            char_overlap = len(set(category.replace(' ', '')) & set(answer.replace(' ', '')))\n",
        "\n",
        "            feature_vector = [\n",
        "                tfidf_similarity,\n",
        "                jaccard_similarity,\n",
        "                common_words,\n",
        "                answer_length,\n",
        "                category_length,\n",
        "                length_ratio,\n",
        "                char_overlap,\n",
        "                abs(answer_length - category_length),  # Length difference\n",
        "            ]\n",
        "\n",
        "            features.append(feature_vector)\n",
        "\n",
        "        self.feature_names = [\n",
        "            'tfidf_similarity', 'jaccard_similarity', 'common_words',\n",
        "            'answer_length', 'category_length', 'length_ratio',\n",
        "            'char_overlap', 'length_diff'\n",
        "        ]\n",
        "\n",
        "        return np.array(features)\n",
        "\n",
        "    def extract_sentence_transformer_features(self, categories, answers):\n",
        "        if not SENTENCE_TRANSFORMERS_AVAILABLE:\n",
        "            raise ImportError(\"sentence-transformers library not available\")\n",
        "\n",
        "        if self.sentence_model is None:\n",
        "            self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "        category_embeddings = self.sentence_model.encode(\n",
        "            categories,\n",
        "            batch_size=32,\n",
        "            show_progress_bar=True,\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "        answer_embeddings = self.sentence_model.encode(\n",
        "            answers,\n",
        "            batch_size=32,\n",
        "            show_progress_bar=True,\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "        features = []\n",
        "        embedding_dim = category_embeddings.shape[1]\n",
        "\n",
        "        for i in range(len(categories)):\n",
        "            cat_emb = category_embeddings[i]\n",
        "            ans_emb = answer_embeddings[i]\n",
        "            cosine_sim = np.dot(cat_emb, ans_emb) / (\n",
        "                np.linalg.norm(cat_emb) * np.linalg.norm(ans_emb)\n",
        "            )\n",
        "            euclidean_dist = np.linalg.norm(cat_emb - ans_emb)\n",
        "            euclidean_normalized = euclidean_dist / np.sqrt(embedding_dim)\n",
        "            element_product = cat_emb * ans_emb\n",
        "            element_diff = cat_emb - ans_emb\n",
        "            abs_diff = np.abs(element_diff)\n",
        "            product_mean = np.mean(element_product)\n",
        "            product_std = np.std(element_product)\n",
        "            diff_mean = np.mean(abs_diff)\n",
        "            diff_std = np.std(abs_diff)\n",
        "\n",
        "            category = categories[i]\n",
        "            answer = answers[i]\n",
        "            cat_words = set(category.split())\n",
        "            ans_words = set(answer.split())\n",
        "\n",
        "            common_words = len(cat_words & ans_words)\n",
        "            jaccard_similarity = common_words / len(cat_words | ans_words) if len(cat_words | ans_words) > 0 else 0\n",
        "\n",
        "            feature_vector = np.concatenate([\n",
        "                [cosine_sim, euclidean_normalized, product_mean, product_std,\n",
        "                 diff_mean, diff_std, jaccard_similarity, len(answer.split()),\n",
        "                 len(category.split()), common_words],\n",
        "                element_product[:50],\n",
        "                abs_diff[:50]\n",
        "            ])\n",
        "\n",
        "            features.append(feature_vector)\n",
        "\n",
        "        self.feature_names = (['cosine_sim', 'euclidean_dist', 'product_mean', 'product_std',\n",
        "                              'diff_mean', 'diff_std', 'jaccard_sim', 'ans_len', 'cat_len', 'common_words'] +\n",
        "                             [f'element_product_{i}' for i in range(50)] +\n",
        "                             [f'abs_diff_{i}' for i in range(50)])\n",
        "\n",
        "        return np.array(features)\n",
        "\n",
        "    def load_and_preprocess_data(self, file_paths):\n",
        "        all_data = []\n",
        "        for file_path in file_paths:\n",
        "            if os.path.exists(file_path):\n",
        "                try:\n",
        "                    df = pd.read_csv(file_path)\n",
        "                    all_data.append(df)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading {file_path}: {e}\")\n",
        "            else:\n",
        "                print(f\"File not found: {file_path}\")\n",
        "\n",
        "        if not all_data:\n",
        "            raise ValueError(\"No valid data files found!\")\n",
        "\n",
        "        combined_df = pd.concat(all_data, ignore_index=True)\n",
        "        df = combined_df.copy()\n",
        "        df['category_clean'] = df['category'].apply(self.clean_text)\n",
        "        df['answer_clean'] = df['answer'].apply(self.clean_text)\n",
        "        initial_rows = len(df)\n",
        "        df = df[(df['category_clean'] != '') & (df['answer_clean'] != '')]\n",
        "        df['relevance_score'] = pd.to_numeric(df['relevance_score'], errors='coerce')\n",
        "        df = df[df['relevance_score'].notna()]\n",
        "        df = df[(df['relevance_score'] >= 0) & (df['relevance_score'] <= 1)]\n",
        "        final_rows = len(df)\n",
        "        return df\n",
        "\n",
        "    def train(self, df):\n",
        "        categories = df['category_clean'].tolist()\n",
        "        answers = df['answer_clean'].tolist()\n",
        "        y = df['relevance_score'].values\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        if self.approach in ['basic', 'auto']:\n",
        "            try:\n",
        "                X = self.extract_basic_features(categories, answers)\n",
        "                if self.approach == 'auto':\n",
        "                    self.approach = 'basic'\n",
        "            except Exception as e:\n",
        "                print(f\"Basic features extraction failed: {e}\")\n",
        "                raise\n",
        "\n",
        "        elif self.approach == 'sentence_transformer':\n",
        "            try:\n",
        "                X = self.extract_sentence_transformer_features(categories, answers)\n",
        "            except Exception as e:\n",
        "                print(f\"Sentence transformer features failed: {e}\")\n",
        "                print(\"Falling back to basic features...\")\n",
        "                X = self.extract_basic_features(categories, answers)\n",
        "                self.approach = 'basic'\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown approach: {self.approach}\")\n",
        "\n",
        "        feature_extraction_time = time.time() - start_time\n",
        "        print(f\"Feature extraction completed: {X.shape[1]} features in {feature_extraction_time:.2f}s\")\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=None\n",
        "        )\n",
        "\n",
        "        models_to_try = {\n",
        "            'random_forest': RandomForestRegressor(\n",
        "                n_estimators=100,\n",
        "                max_depth=10,\n",
        "                random_state=42\n",
        "            ),\n",
        "            'gradient_boosting': GradientBoostingRegressor(\n",
        "                n_estimators=200,\n",
        "                learning_rate=0.1,\n",
        "                max_depth=6,\n",
        "                random_state=42\n",
        "            ),\n",
        "            'linear_regression': LinearRegression(),\n",
        "            'neural_network': MLPRegressor(\n",
        "                hidden_layer_sizes=(100, 50),\n",
        "                max_iter=500,\n",
        "                random_state=42\n",
        "            )\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        for model_name, model in models_to_try.items():\n",
        "            try:\n",
        "                print(f\"\\nTraining {model_name}\")\n",
        "\n",
        "                needs_scaling = model_name in ['neural_network', 'linear_regression']\n",
        "\n",
        "                if needs_scaling:\n",
        "                    if self.scaler is None:\n",
        "                        self.scaler = StandardScaler()\n",
        "                    X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "                    X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "                    model.fit(X_train_scaled, y_train)\n",
        "                    y_pred = model.predict(X_test_scaled)\n",
        "                else:\n",
        "                    model.fit(X_train, y_train)\n",
        "                    y_pred = model.predict(X_test)\n",
        "\n",
        "                y_pred = np.clip(y_pred, 0, 1)\n",
        "\n",
        "                mse = mean_squared_error(y_test, y_pred)\n",
        "                mae = mean_absolute_error(y_test, y_pred)\n",
        "                r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "                results[model_name] = {\n",
        "                    'model': model,\n",
        "                    'mse': mse,\n",
        "                    'mae': mae,\n",
        "                    'r2': r2,\n",
        "                    'needs_scaling': needs_scaling\n",
        "                }\n",
        "\n",
        "                print(f\"   MSE: {mse:.4f} | MAE: {mae:.4f} | R²: {r2:.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   Failed to train {model_name}: {e}\")\n",
        "\n",
        "        if results:\n",
        "            best_model_name = max(results.keys(), key=lambda k: results[k]['r2'])\n",
        "            best_result = results[best_model_name]\n",
        "\n",
        "            self.model = best_result['model']\n",
        "            self.model_name = best_model_name\n",
        "\n",
        "            if not best_result['needs_scaling']:\n",
        "                self.scaler = None\n",
        "\n",
        "            training_time = time.time() - start_time\n",
        "\n",
        "            self.training_stats = {\n",
        "                'approach': self.approach,\n",
        "                'model_name': best_model_name,\n",
        "                'training_samples': len(df),\n",
        "                'feature_count': X.shape[1],\n",
        "                'training_time': training_time,\n",
        "                'feature_extraction_time': feature_extraction_time,\n",
        "                'needs_scaling': best_result['needs_scaling'],\n",
        "                'mse': best_result['mse'],\n",
        "                'mae': best_result['mae'],\n",
        "                'r2': best_result['r2'],\n",
        "                'all_results': {k: {kk: vv for kk, vv in v.items() if kk != 'model'}\n",
        "                               for k, v in results.items()}\n",
        "            }\n",
        "\n",
        "            print(f\"\\nBest model: {best_model_name}\")\n",
        "            print(f\"Training completed in {training_time:.2f}s\")\n",
        "            print(f\"Performance: R² = {best_result['r2']:.4f}, MAE = {best_result['mae']:.4f}\")\n",
        "\n",
        "            return self.training_stats\n",
        "        else:\n",
        "            raise ValueError(\"All models failed to train!\")\n",
        "\n",
        "    def predict(self, category, answer):\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained yet! Call train() first.\")\n",
        "\n",
        "        category_clean = self.clean_text(category)\n",
        "        answer_clean = self.clean_text(answer)\n",
        "\n",
        "        if self.approach == 'basic':\n",
        "            features = self.extract_basic_features([category_clean], [answer_clean])\n",
        "        elif self.approach == 'sentence_transformer':\n",
        "            features = self.extract_sentence_transformer_features([category_clean], [answer_clean])\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown approach: {self.approach}\")\n",
        "\n",
        "        if self.scaler is not None:\n",
        "            features = self.scaler.transform(features)\n",
        "\n",
        "        prediction = self.model.predict(features)[0]\n",
        "        return np.clip(prediction, 0, 1)\n",
        "\n",
        "    def predict_batch(self, categories, answers):\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained yet! Call train() first.\")\n",
        "\n",
        "        categories_clean = [self.clean_text(cat) for cat in categories]\n",
        "        answers_clean = [self.clean_text(ans) for ans in answers]\n",
        "\n",
        "        if self.approach == 'basic':\n",
        "            features = self.extract_basic_features(categories_clean, answers_clean)\n",
        "        elif self.approach == 'sentence_transformer':\n",
        "            features = self.extract_sentence_transformer_features(categories_clean, answers_clean)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown approach: {self.approach}\")\n",
        "\n",
        "        if self.scaler is not None:\n",
        "            features = self.scaler.transform(features)\n",
        "\n",
        "        predictions = self.model.predict(features)\n",
        "        return np.clip(predictions, 0, 1)\n",
        "\n",
        "    def save_model(self, filepath):\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"No model to save! Train the model first.\")\n",
        "\n",
        "        model_data = {\n",
        "            'approach': self.approach,\n",
        "            'model_name': self.model_name,\n",
        "            'model': self.model,\n",
        "            'vectorizer': self.vectorizer,\n",
        "            'scaler': self.scaler,\n",
        "            'feature_names': self.feature_names,\n",
        "            'training_stats': self.training_stats,\n",
        "            'sentence_model_name': 'all-MiniLM-L6-v2' if self.approach == 'sentence_transformer' else None\n",
        "        }\n",
        "\n",
        "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
        "\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(model_data, f)\n",
        "\n",
        "        print(f\"Model saved to {filepath}\")\n",
        "        print(f\"Approach: {self.approach}\")\n",
        "        print(f\"Model: {self.model_name}\")\n",
        "        print(f\"Features: {len(self.feature_names)}\")\n",
        "\n",
        "    def load_model(self, filepath):\n",
        "        with open(filepath, 'rb') as f:\n",
        "            model_data = pickle.load(f)\n",
        "\n",
        "        self.approach = model_data['approach']\n",
        "        self.model_name = model_data['model_name']\n",
        "        self.model = model_data['model']\n",
        "        self.vectorizer = model_data['vectorizer']\n",
        "        self.scaler = model_data['scaler']\n",
        "        self.feature_names = model_data['feature_names']\n",
        "        self.training_stats = model_data['training_stats']\n",
        "\n",
        "        if self.approach == 'sentence_transformer' and SENTENCE_TRANSFORMERS_AVAILABLE:\n",
        "            print(\"Loading sentence transformer model...\")\n",
        "            self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "        print(f\"Model loaded from {filepath}\")\n",
        "        print(f\"Approach: {self.approach}\")\n",
        "        print(f\"Model: {self.model_name}\")\n",
        "        print(f\"Performance: R² = {self.training_stats['r2']:.4f}\")\n"
      ],
      "metadata": {
        "id": "Y-lCegS90Kfe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_files = [\n",
        "    'chaotic_categories_data.csv',\n",
        "    'chaotic_categories_dataset 1.csv',\n",
        "    'chaotic_categories_dataset 2.csv',\n",
        "    'chaotic_categories_dataset 3.csv'\n",
        "]\n",
        "\n",
        "test_cases = [\n",
        "    (\"Things You Can Use as a Hat (that are not hats)\", \"A watermelon half\", 0.95),\n",
        "    (\"Things You Can Use as a Hat (that are not hats)\", \"A colander\", 0.92),\n",
        "    (\"Things You Can Use as a Hat (that are not hats)\", \"Eat rice\", 0.05),\n",
        "    (\"Ways to Avoid Paying a Debt\", \"Move to another country\", 0.85),\n",
        "    (\"Ways to Avoid Paying a Debt\", \"Change identity to an alpaca\", 0.65),\n",
        "    (\"Ways to Avoid Paying a Debt\", \"Buy groceries\", 0.10),\n",
        "    (\"Unconvincing Superpowers\", \"The ability to fly very slowly\", 0.90),\n",
        "    (\"Unconvincing Superpowers\", \"Make toast appear\", 0.20),\n",
        "]\n",
        "\n",
        "approaches = ['basic']\n",
        "if SENTENCE_TRANSFORMERS_AVAILABLE:\n",
        "    approaches.append('sentence_transformer')\n",
        "\n",
        "results = {}\n",
        "\n",
        "for approach in approaches:\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"TESTING APPROACH: {approach.upper()}\")\n",
        "    print(f\"{'=' * 60}\")\n",
        "\n",
        "    try:\n",
        "        checker = RelevanceChecker(approach=approach)a\n",
        "        df = checker.load_and_preprocess_data(data_files)\n",
        "        training_stats = checker.train(df)\n",
        "        model_path = f\"models/relevance_checker_{approach}.pkl\"\n",
        "        os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "        checker.save_model(model_path)\n",
        "        print(\"\\nPrediction Results:\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        for category, answer, expected in test_cases:\n",
        "            try:\n",
        "                prediction = checker.predict(category, answer)\n",
        "                diff = abs(prediction - expected)\n",
        "                if diff < 0.3:\n",
        "                    status = \"PASS\"\n",
        "                elif diff < 0.5:\n",
        "                    status = \"WARNING\"\n",
        "                else:\n",
        "                    status = \"FAIL\"\n",
        "\n",
        "                print(f\"{status} - Category: {category[:50]}\")\n",
        "                print(f\"  Answer: {answer}\")\n",
        "                print(f\"  Predicted: {prediction:.3f} | Expected: {expected:.3f} | Difference: {diff:.3f}\\n\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"ERROR - Failed to predict for '{answer}' in category '{category}': {e}\")\n",
        "\n",
        "        results[approach] = {\n",
        "            'checker': checker,\n",
        "            'stats': training_stats,\n",
        "            'model_path': model_path\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR - Approach '{approach}' encountered an exception:\\n{e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "if results:\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(\"FINAL SUMMARY\")\n",
        "    print(f\"{'=' * 60}\")\n",
        "\n",
        "    for approach, result in results.items():\n",
        "        stats = result['stats']\n",
        "        print(f\"\\nApproach: {approach.upper()}\")\n",
        "        print(f\"  Model Name       : {stats.get('model_name', 'N/A')}\")\n",
        "        print(f\"  R² Score         : {stats.get('r2', 0.0):.4f}\")\n",
        "        print(f\"  MAE              : {stats.get('mae', 0.0):.4f}\")\n",
        "        print(f\"  Feature Count    : {stats.get('feature_count', 'N/A')}\")\n",
        "        print(f\"  Training Duration: {stats.get('training_time', 0.0):.2f} seconds\")\n",
        "        print(f\"  Model File Path  : {result['model_path']}\")\n",
        "\n",
        "    best_approach = max(results.keys(), key=lambda k: results[k]['stats'].get('r2', 0))\n",
        "    print(f\"\\nrecommended approach: {best_approach.upper()}\")\n",
        "    print(f\"  Best R² Score: {results[best_approach]['stats']['r2']:.4f}\")"
      ],
      "metadata": {
        "id": "xnauucYGm_Yq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}